# -*- coding: utf-8 -*-
"""LoveClockProject2.0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nQpjmnmL4z9627WMoRs5v1oBsrZoyI6f

# **Importing Libraries and Things**
"""

#importing libraries
import math
import pandas as pd
import numpy as np
from numpy import mean
from numpy import std
from matplotlib import pyplot
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.inspection import permutation_importance
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
from xgboost import XGBRegressor

#access data
df = pd.read_csv("/content/dataset.csv")

#replace the categorical data into numerical
def gender_to_numeric(x):
  if x=='Male':
    return 0
  else:
    return 1

def academic_to_numeric(x):
  if x=='Degree' or x=='Diploma' or x=='Postgraduates':
    return 1
  else:
    return 0

df['Gender_Num'] = df['Gender'].apply(gender_to_numeric)
df['Academic_Num'] = df['Gender'].apply(academic_to_numeric)

#dropping the column 
df = df.drop('Gender',1)
df = df.drop('AcademicLevel', 1)


#refined dataset
LoveData = df
LoveData

"""# **Finding Outlier In The Data**"""

#Age
pyplot.hist(LoveData.Age)
pyplot.xlabel("Age")
pyplot.ylabel("Frequency")
pyplot.show()
pyplot.boxplot(LoveData.Age)
pyplot.xlabel("Age")
pyplot.show()
pyplot.scatter(LoveData.Age, LoveData.AvgInteract)
pyplot.xlabel("Age")
pyplot.ylabel("Average Interaction")

"""This dataset is skewed and needed to be changed"""

LoveData.Age.describe()

#Testing how to find outliers
max_threshold = LoveData['Age'].quantile(0.92) #everything above this is considered as an outlier
print(max_threshold)
#remove all the outlier in the data
LoveData = LoveData[LoveData['Age'] < max_threshold]
pyplot.hist(LoveData.Age)
pyplot.xlabel("Age")
pyplot.ylabel("Frequency")
pyplot.show()

#AvgInteract
pyplot.hist(LoveData.AvgInteract)
pyplot.xlabel("Average Interaction")
pyplot.ylabel("Frequency")
pyplot.show()

#StudyHour
pyplot.hist(LoveData.StdyHour)
pyplot.xlabel("Study Hours")
pyplot.ylabel("Frequency")
pyplot.show()

#BffTime
pyplot.hist(LoveData.BffTime)
pyplot.xlabel("Time Spent With BFF")
pyplot.ylabel("Frequency")
pyplot.show()

#HobbyHour
pyplot.hist(LoveData.HobbyHour)
pyplot.xlabel("Time Spent on Hobbies")
pyplot.ylabel("Frequency")
pyplot.show()

#SleepHour
pyplot.hist(LoveData.SleepHour)
pyplot.xlabel("Average Sleep Hours")
pyplot.ylabel("Frequency")
pyplot.show()

#Gender
pyplot.hist(LoveData.Gender_Num)
pyplot.xlabel("Gender")
pyplot.ylabel("Frequency")
pyplot.show()

#AcademicLevel
pyplot.hist(LoveData.Academic_Num)
pyplot.xlabel("Academic Types")
pyplot.ylabel("Frequency")
pyplot.show()

"""# **Training and Test Data**"""

X = LoveData.drop("AvgInteract", 1)
y = LoveData["AvgInteract"]

#splitting the data for training and testing
x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.2) #test size is 20% of the dataset

#printing the shapes of testing and training dataset
print("shape of original dataset :", LoveData.shape)
print("shape of input - training set", x_train.shape)
print("shape of output - training set", y_train.shape)
print("shape of input - testing set", x_test.shape)
print("shape of output - testing set", y_test.shape)

x_test

"""# **Selecting Feature and Testing Model**

## **Linear Regression Feature Importance**
"""

#define the model
model = LinearRegression()
#fit the model
model.fit(x_train,y_train)
#get importance
importance = model.coef_
#summarize feature importance
for i,v in enumerate(importance):
  print('Feature : %0d, Score: %.5f' % (i,v))

#plotting the feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

"""## **CART Regression Feature Importance**"""

#define the model
model = DecisionTreeRegressor()
#fit the model
model.fit(x_train,y_train)
#get importance
importance = model.feature_importances_
#summarize feature importance
for i,v in enumerate(importance):
  print('Feature : %0d, Score: %.5f' % (i,v))

#plotting the feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

"""## **Random Forest Regression Feature Importance**"""

#Finding MAE value
#define the model
model = RandomForestRegressor()
#fit the model
model.fit(x_train,y_train)
#get importance
importance = model.feature_importances_
#summarize feature importance
for i,v in enumerate(importance):
  print('Feature : %0d, Score: %.5f' % (i,v))

# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

"""## **XGBoost Regression Feature Importance**"""

#define the model
model = XGBRegressor()
#fit the model
model.fit(x_train,y_train)
#get importance
importance = model.feature_importances_
#summarize feature importance
for i,v in enumerate(importance):
  print('Feature : %0d, Score: %.5f' % (i,v))

# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

"""## **Permutation Feature Importance**"""

#define the model
model = KNeighborsRegressor()
#fit the model
model.fit(x_train,y_train)
# perform permutation importance
results = permutation_importance(model, x_train,y_train, scoring='neg_mean_squared_error')
#get importance
importance = results.importances_mean
#summarize feature importance
for i,v in enumerate(importance):
  print('Feature : %0d, Score: %.5f' % (i,v))

# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

"""# **MAE Values**"""

#LinearRegression
X = x_train.drop("Age",1)
X = X.drop("StdyHour", 1)
X = X.drop("BffTime",1)
X = X.drop("Academic_Num",1)
y = y_train

model = LinearRegression()
model.fit(X,y)
#Finding MAE value
# define the evaluation procedure
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate the model and collect results
n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)
# report performance
print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))

#CART
X = x_train.drop("Gender_Num",1)
X = x_train.drop("Academic_Num",1)
y = y_train

model = DecisionTreeRegressor()
model.fit(X,y)
#Finding MAE value
# define the evaluation procedure
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate the model and collect results
n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)
# report performance
print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))

#Random Forest
X = x_train.drop("Gender_Num",1)
X = X.drop("Academic_Num",1)
y = y_train

model = RandomForestRegressor()
model.fit(X,y)
#Finding MAE value
# define the evaluation procedure
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate the model and collect results
n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)
# report performance
print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))

#XGBoost
X = x_train.drop("StdyHour",1)
X = X.drop("Academic_Num",1)
y = y_train

model = XGBRegressor()
model.fit(X,y)
#Finding MAE value
# define the evaluation procedure
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate the model and collect results
n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)
# report performance
print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))

#Permutation
X = x_train.drop("Gender_Num",1)
X = X.drop("Academic_Num",1)
y = y_train

model = KNeighborsRegressor()
model.fit(X,y)
#Finding MAE value
# define the evaluation procedure
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate the model and collect results
n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)
# report performance
print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))

"""# **Fitting The Random Forest Regression Model**"""

#Random Forest Regression
X = x_train.drop("Gender_Num",1)
X = X.drop("Academic_Num",1)
y = y_train

#Dropping features in the test dataset
X_test = x_test.drop("Gender_Num",1)
X_test = X_test.drop("Academic_Num",1)

#Fitting Random Forest Regression to the dataset
model = RandomForestRegressor()
model.fit(X,y)

#Predicting the result
y_pred = model.predict(X_test)

#Comparison dataframe
pred_df = pd.DataFrame({'Real Values':y_test, 'Predicted Values':y_pred.reshape(-1)})
#calculate accuracy
# Calculate mean absolute percentage error (MAPE)
mape = mean_absolute_error(y_test, y_pred) 
# Calculate and display accuracy
accuracy = 100 - mape    
#print result
print('Initial model achieves on the test set an accuracy of', round(accuracy, 2),'%')

"""### **Fine Tuning the Random Forest Model**

Grid Search
"""

from sklearn.model_selection import GridSearchCV

param_grid = [
{'n_estimators': [10, 25],
 'max_depth': [10, 50, None], 'bootstrap': [True, False]}
]

grid_search_forest = GridSearchCV(RandomForestRegressor(), param_grid, cv=10, scoring='neg_mean_squared_error')
grid_search_forest.fit(X,y)


cvres = grid_search_forest.cv_results_
for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
    print(np.sqrt(-mean_score), params)

#find the best model of grid search
grid_search_forest.best_estimator_

# Performance metrics
grid_best= grid_search_forest.best_estimator_.predict(X)
errors = abs(grid_best - y)
# Calculate mean absolute percentage error (MAPE)
mape = mean_absolute_error(y, grid_best)
# Calculate and display accuracy
accuracy = 100 - mape    
#print result
print('The best model from grid-search has an accuracy of', round(accuracy, 2),'%')

"""# **Evaluating The Model On The Test Set**"""

final_model = grid_search_forest.best_estimator_
# Predicting test set results
final_pred = final_model.predict(X_test) 
final_mse = mean_squared_error(y_test, final_pred)
final_rmse = np.sqrt(final_mse)
print('The final RMSE on the test set is', round(final_rmse, 2))

#calculate accuracy
errors = abs(final_pred - y_test)
# Calculate mean absolute percentage error (MAPE)
mape = mean_absolute_error(y_test, final_pred)
# Calculate and display accuracy
accuracy = 100 - mape    
#print result
print('The best model achieves on the test set an accuracy of', round(accuracy, 2),'%')

"""# **Visualization of Random Forest Hyperparameters**

---
## Getting the accuracy

"""

max_depths = np.linspace(1, 100, 100, endpoint=True)

train_results = []
test_results = []

for i in max_depths:
    dt = RandomForestRegressor(max_depth=i)
    dt.fit(X, y)    
    #compute accuracy for train data
    housing_tree = dt.predict(X)
    # Calculate mean absolute percentage error (MAPE)
    mape = mean_absolute_error(y, housing_tree)
    # Calculate and display accuracy
    accuracy = 100 - np.mean(mape)
    #append results of accuracy
    train_results.append(accuracy)
    
    #now again for test data
    housing_tree = dt.predict(X_test)
    # Calculate mean absolute percentage error (MAPE)
    mape = mean_absolute_error(y_test, housing_tree)
    # Calculate and display accuracy
    accuracy = 100 - np.mean(mape)
    #append results of accuracy
    test_results.append(accuracy)
    
from matplotlib.legend_handler import HandlerLine2D
line1, = pyplot.plot(max_depths, train_results, 'b', label='Train accuracy')
line2, = pyplot.plot(max_depths, test_results, 'r', label= 'Test accuracy')

pyplot.legend(handler_map={line1: HandlerLine2D(numpoints=2)})
pyplot.ylabel('Accuracy score')
pyplot.xlabel('Tree depth')

X_test

"""# **Testing A Specific Data**"""

#Testing a specific data
X_test

#20, 4, 2, 0, 6

test_test = { 'Age' : [20],'StdyHour' : [4], 'BffTime' : [2], 'HobbyHour' : [0] , 'SleepHour' : [6]}
test_DF = pd.DataFrame(test_test, columns = ['Age', 'StdyHour', 'BffTime', 'HobbyHour', 'SleepHour'])
test_pred = final_model.predict(test_DF)
test_pred/4

